import torch
# ################################## 关于expand、tile、repeat矩阵复制 ##################################
x1 = torch.randn(3)
print(x1)
x2 = x1.expand(4,3)
print(x2)
x2[1][1] = 1
print(x1)
print(x1.data_ptr(), x2.data_ptr())
print(x1.stride(), x2.stride())
# tensor([ 0.7171, -1.0192, -0.1841])
# tensor([[ 0.7171, -1.0192, -0.1841],
#         [ 0.7171, -1.0192, -0.1841],
#         [ 0.7171, -1.0192, -0.1841],
#         [ 0.7171, -1.0192, -0.1841]])
# tensor([ 0.7171,  1.0000, -0.1841])
# 535643058496 535643058496
# (1,) (0, 1)

# 小结：expand 一般使用在 tensor的shape含有1的张量，而且expand是生成视图，地址还是共享的

x3 = torch.randn(2, 3)
print(x3)
x4 = x3.repeat(2, 2)
print(x4)
x4[0][0] = 1
print(x3)
print(x4)
print(x3.data_ptr(), x4.data_ptr())
print(x3.stride(), x4.stride())
# tensor([[ 0.0592, -1.5846, -2.0300],
#         [ 0.9810, -0.2108,  0.2842]])
# tensor([[ 0.0592, -1.5846, -2.0300,  0.0592, -1.5846, -2.0300],
#         [ 0.9810, -0.2108,  0.2842,  0.9810, -0.2108,  0.2842],
#         [ 0.0592, -1.5846, -2.0300,  0.0592, -1.5846, -2.0300],
#         [ 0.9810, -0.2108,  0.2842,  0.9810, -0.2108,  0.2842]])
# tensor([[ 0.0592, -1.5846, -2.0300],
#         [ 0.9810, -0.2108,  0.2842]])
# tensor([[ 1.0000, -1.5846, -2.0300,  0.0592, -1.5846, -2.0300],
#         [ 0.9810, -0.2108,  0.2842,  0.9810, -0.2108,  0.2842],
#         [ 0.0592, -1.5846, -2.0300,  0.0592, -1.5846, -2.0300],
#         [ 0.9810, -0.2108,  0.2842,  0.9810, -0.2108,  0.2842]])
# 915861417664 915861019072
# (3, 1) (6, 1)
# 小结，repeat是拷贝层次的复制，复制后不会共享地址

import numpy as np
# x5 = np.random.randn(2, 3)
# x6 = np.tile(x5, (2, 2))
# print(x5)
# print(x6)
# x6[0][0] = 1
# print(x5)
# print(x6)
# [[ 0.38983702 -0.47648074  0.15614018]
#  [ 0.87656863  0.58530332  0.79826045]]
# [[ 0.38983702 -0.47648074  0.15614018  0.38983702 -0.47648074  0.15614018]
#  [ 0.87656863  0.58530332  0.79826045  0.87656863  0.58530332  0.79826045]
#  [ 0.38983702 -0.47648074  0.15614018  0.38983702 -0.47648074  0.15614018]
#  [ 0.87656863  0.58530332  0.79826045  0.87656863  0.58530332  0.79826045]]
# [[ 0.38983702 -0.47648074  0.15614018]
#  [ 0.87656863  0.58530332  0.79826045]]
# [[ 1.         -0.47648074  0.15614018  0.38983702 -0.47648074  0.15614018]
#  [ 0.87656863  0.58530332  0.79826045  0.87656863  0.58530332  0.79826045]
#  [ 0.38983702 -0.47648074  0.15614018  0.38983702 -0.47648074  0.15614018]
#  [ 0.87656863  0.58530332  0.79826045  0.87656863  0.58530332  0.79826045]]


# expand内存共享，针对含有维度1的tensor
# repeat内部不共享，针对所有tensor，等价于np里面的tile

